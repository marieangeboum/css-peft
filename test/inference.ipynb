{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0dc996dde6a1671",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T19:24:52.949223Z",
     "start_time": "2024-08-26T19:24:52.916066Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from easydict import EasyDict\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "import matplotlib.patches as mpatches\n",
    "from configs.utils import load_config_yaml, update_domain_sequence\n",
    "from dl_toolbox.callbacks import *\n",
    "import dl_toolbox.inference as dl_inf\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from model.segmenter_adapt import SegmenterAdapt\n",
    "from datasets.utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73abdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/d/maboum/css-peft/configs/config.yml\"\n",
    "config = load_config_yaml(file_path=config_file)\n",
    "data_config = config[\"dataset\"][\"flair1\"]\n",
    "binary = data_config[\"binary\"]\n",
    "directory_path = data_config[\"data_path\"]\n",
    "seed = config[\"seed\"]\n",
    "random.seed(seed)\n",
    "selected_elements = random.sample(os.listdir(directory_path), 20)\n",
    "update_domain_sequence(config_file, selected_elements)\n",
    "remaining_elements = list(filter(lambda element: element not in selected_elements, os.listdir(directory_path)))\n",
    "update_domain_sequence(config_file, remaining_elements, 'task_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a767e7fdb850dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T19:24:52.999721Z",
     "start_time": "2024-08-26T19:24:52.971974Z"
    }
   },
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    initial_lr=0.01,\n",
    "    final_lr=0.005,\n",
    "    lr_milestones=(20, 80),\n",
    "    epoch_len=100,\n",
    "    sup_batch_size=4,\n",
    "    crop_size=256,\n",
    "    workers=6,\n",
    "    img_aug='d4_rot90_rot270_rot180_d1flip',\n",
    "    max_epochs=200,\n",
    "    sequence_path=\"\",\n",
    "    train_split_coef=0.85,\n",
    "    strategy='continual_{}',\n",
    "    commit=None,\n",
    "    train_type=\"adaptmlp\",\n",
    "    replay=False,  # Par défaut, `store_true` est `False`\n",
    "    config_file=\"/d/maboum/css-peft/configs/config.yml\",\n",
    "    ffn_adapt=True,  # Par défaut, `store_true` est `True`\n",
    "    ffn_num=64,\n",
    "    vpt=False,  # Par défaut, `store_true` est `False`\n",
    "    vpt_num=1,\n",
    "    fulltune=False  # Par défaut, `store_true` est `False`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b736925d3ad85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention(image, attention_map, save_path=None):\n",
    "    \"\"\"Visualize the image with its corresponding attention map.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Original Image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # Attention Map\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(attention_map, cmap='viridis')\n",
    "    plt.title(\"Attention Map\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe5623610cb82f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T19:24:53.027810Z",
     "start_time": "2024-08-26T19:24:53.005598Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_function(model, test_dataloader, device, loss_fn, accuracy_fn, data_config, run=None, eval_freq=5):\n",
    "    n_channels = data_config['n_channels']\n",
    "    class_labels = data_config['classnames']\n",
    "    n_class = data_config['n_cls']\n",
    "    labels = [class_labels[i] for i in sorted(class_labels.keys())]\n",
    "\n",
    "\n",
    "    # Initialize accumulators\n",
    "    loss_sum, acc_sum = 0.0, 0.0\n",
    "    iou_metrics = torch.zeros(n_class)\n",
    "    confusion_matrices = []\n",
    "\n",
    "    for i, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        # Preprocess input and target\n",
    "        image = (batch['image'][:, :n_channels, :, :] / 255.).to(device)\n",
    "        target = batch['mask'].to(device)\n",
    "\n",
    "        # Model forward pass\n",
    "        output = model(image)\n",
    "        softmax_output = F.softmax(output, dim=1)\n",
    "\n",
    "        # Compute loss and accuracy\n",
    "        loss = loss_fn(softmax_output, target.squeeze(1).long())\n",
    "        acc = accuracy_fn(softmax_output.argmax(dim=1).unsqueeze(1), target)\n",
    "\n",
    "        # Update accumulators\n",
    "        loss_sum += loss.item()\n",
    "        acc_sum += acc\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = compute_conf_mat(\n",
    "            target.contiguous().view(-1).cpu(),\n",
    "            output.argmax(dim=1).contiguous().view(-1).cpu().long(),\n",
    "            n_class\n",
    "        )\n",
    "        confusion_matrices.append(cm.numpy())\n",
    "\n",
    "        # Compute IoU for each class\n",
    "        metrics_per_class_df, _, _ = dl_inf.cm2metrics(cm.numpy())\n",
    "        # metrics_per_class_df.rename(index=class_labels, inplace=True).round(3)\n",
    "        iou_metrics += torch.tensor(metrics_per_class_df.IoU.values)\n",
    "\n",
    "        # Evaluate and log images at specific intervals\n",
    "        if i % eval_freq == 0:\n",
    "            idx_list = [0, -1]  # Display first and last images in the batch\n",
    "            for img_idx in idx_list:\n",
    "                domain_id = batch['id'][img_idx] if 'id' in batch else i  # Default to batch index if no domain_id\n",
    "                img_cm = compute_conf_mat(\n",
    "                    target[img_idx].contiguous().view(-1).cpu(),\n",
    "                    output.argmax(dim=1)[img_idx].contiguous().view(-1).cpu().long(),\n",
    "                    n_class\n",
    "                )\n",
    "                img_metrics_per_class_df, _, _ = dl_inf.cm2metrics(img_cm.numpy())\n",
    "\n",
    "                # Plot predictions and ground truth\n",
    "                predictions = overlay_segmentation(\n",
    "                    image[img_idx].permute(1, 2, 0).cpu().numpy(),\n",
    "                    output.argmax(dim=1)[img_idx].cpu().numpy(),\n",
    "                    class_labels\n",
    "                )\n",
    "                ground_truth = overlay_segmentation(\n",
    "                    image[img_idx].permute(1, 2, 0).cpu().numpy(),\n",
    "                    target[img_idx, 0].cpu().numpy(),\n",
    "                    class_labels\n",
    "                )\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(15, 7.5))\n",
    "                axs[0].imshow(predictions)\n",
    "                axs[0].set_title(\"Predictions\")\n",
    "                axs[0].axis('off')\n",
    "                axs[1].imshow(ground_truth)\n",
    "                axs[1].set_title(\"Ground Truth\")\n",
    "                axs[1].axis('off')\n",
    "\n",
    "                # Legend\n",
    "                legend_patches = [\n",
    "                    mpatches.Patch(color=plt.cm.tab20(j / len(class_labels)), label=class_labels[j])\n",
    "                    for j in class_labels\n",
    "                ]\n",
    "                fig.legend(handles=legend_patches, loc='upper center', ncol=4, bbox_to_anchor=(0.5, 0.11), fontsize='medium')\n",
    "                \n",
    "                fig_path = f\"/d/maboum/css-peft/imgs/logs/_{img_idx}_batch{i}_{domain_id}.png\"\n",
    "                # test_metrics_df.to_csv('test_metrics.txt', sep='\\t')\n",
    "                img_metrics_per_class_df.rename(index=class_labels, inplace=True)\n",
    "                img_metrics_per_class_df.round(3).to_csv(f'/d/maboum/css-peft/imgs/logs/_{img_idx}_batch{i}_{domain_id}.txt', sep='\\t')\n",
    "                # fig.savefig(fig_path)\n",
    "                # print(f\"Figure saved to {fig_path}\")\n",
    "\n",
    "                # Close the figure to free memory\n",
    "                plt.close(fig)\n",
    "                # Log figure\n",
    "                if run:\n",
    "                    run[f'test/batch_{i}/domain_{domain_id}'].upload(fig)\n",
    "\n",
    "                    # Log IoU metrics for this image\n",
    "                    for cls_idx, cls_name in class_labels.items():\n",
    "                        run[f'test/metrics/{domain_id}_{i}_{cls_name}_iou'].append(\n",
    "                            img_metrics_per_class_df.IoU.loc[cls_idx].round(2)\n",
    "                        )\n",
    "\n",
    "    # Overall metrics and logging\n",
    "    val_loss = loss_sum / len(test_dataloader)\n",
    "    val_acc = acc_sum.item() / len(test_dataloader)\n",
    "    val_iou = torch.mean(iou_metrics) / len(test_dataloader)\n",
    "\n",
    "    mean_cm = sum(confusion_matrices)/len(test_dataloader)\n",
    "    # Compute IoU for each class\n",
    "    test_metrics_df, _, _ = dl_inf.cm2metrics(mean_cm)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Log overall metrics\n",
    "    if run:\n",
    "        run['test/loss'].log(val_loss)\n",
    "        run['test/accuracy'].log(val_acc)\n",
    "        run['test/mean_iou'].log(val_iou)\n",
    "\n",
    "    print(f\"Test Loss: {val_loss:.4f}, Test Accuracy: {val_acc:.4f}, Test Mean IoU: {val_iou:.4f}\")\n",
    "    print(test_metrics_df.round(4))\n",
    "    \n",
    "\n",
    "    return val_loss, val_acc, val_iou, test_metrics_df, mean_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T19:24:53.054300Z",
     "start_time": "2024-08-26T19:24:53.040257Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_and_visualize():\n",
    "    # Configuration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    config_file = \"/d/maboum/css-peft/configs/config.yml\"  # Change this to your actual path\n",
    "    checkpoint_path = \"/scratcht/FLAIR_1/experiments/checkpoints/continual_260824\"\n",
    "    config = load_config_yaml(file_path=config_file)\n",
    "    \n",
    "    seed = config[\"seed\"]\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.autograd.set_detect_anomaly(True) \n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Model setup (assuming similar setup from main training code)\n",
    "    selected_model = \"vit_base_patch8_224\"\n",
    "    model_type = config[\"model\"]\n",
    "    data_sequence =config[\"dataset\"][\"flair1\"][\"task_name\"]\n",
    "    model_config = model_type[selected_model]\n",
    "    im_size = model_config[\"image_size\"]\n",
    "    patch_size = model_config[\"patch_size\"]\n",
    "    d_model = model_config[\"d_model\"]\n",
    "    n_heads = model_config[\"n_heads\"]\n",
    "    n_layers = model_config[\"n_layers\"]\n",
    "    d_encoder = model_config[\"d_model\"]\n",
    "    n_class = config[\"dataset\"][\"flair1\"][\"n_cls\"]\n",
    "    \n",
    "    tuning_config = EasyDict(\n",
    "        ffn_adapt=True,\n",
    "        ffn_option=\"parallel\",\n",
    "        ffn_adapter_layernorm_option=\"none\",\n",
    "        ffn_adapter_init_option=\"lora\",\n",
    "        ffn_adapter_scalar=\"0.1\",\n",
    "        ffn_num=64,\n",
    "        d_model=d_model,\n",
    "        vpt_on=False,\n",
    "        vpt_num=1,\n",
    "        nb_task=len(data_sequence[:5]),\n",
    "        tasks=data_sequence[:5]\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SegmenterAdapt(\n",
    "        im_size, n_layers, d_model, d_encoder, 4 * d_model, n_heads, n_class,\n",
    "        patch_size, selected_model, tuning_config=tuning_config,\n",
    "        model_name=config[\"model_name\"]\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    model.load_pretrained_weights(model_path = checkpoint_path)\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare test data loader\n",
    "    \n",
    "    data_config = config[\"dataset\"][\"flair1\"]\n",
    "    binary = data_config[\"binary\"]\n",
    "    directory_path = data_config[\"data_path\"]\n",
    "    test_dataloaders = []\n",
    "    train_imgs, test_imgs = [],[]\n",
    "    loss_fn = torch.nn.CrossEntropyLoss().cuda()\n",
    "    accuracy_fn = Accuracy(task='multiclass',num_classes=n_class).cuda()\n",
    "    \n",
    "    for step,domain in enumerate(tuning_config.tasks[:1]):\n",
    "        print(step , domain)\n",
    "        img = glob.glob(os.path.join(directory_path, '{}/Z*_*/img/IMG_*.tif'.format(domain)))\n",
    "        random.shuffle(img)\n",
    "        train_imgs += img[:int(len(img)*args.train_split_coef)]\n",
    "        test_imgs += img[int(len(img)*args.train_split_coef):]\n",
    "        random.shuffle(train_imgs)\n",
    "    test_dataloader = create_test_dataloader(test_imgs, args, data_config, binary= binary)\n",
    "    val_loss, val_acc, val_iou, test_metrics_df, mean_cm = test_function(model, test_dataloader, device, loss_fn, accuracy_fn, data_config)\n",
    "    return val_loss, val_acc, val_iou, test_metrics_df, mean_cm\n",
    "val_loss, val_acc, val_iou, test_metrics_df, mean_cm = test_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ae2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97622ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/d/maboum/css-peft/configs/config.yml\"\n",
    "config = load_config_yaml(file_path=config_file)\n",
    "label_dict = config[\"dataset\"][\"flair1\"][\"classnames\"]\n",
    "labels = [label_dict[i] for i in sorted(label_dict.keys())]\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "cm_norm = mean_cm.astype('float')/(mean_cm.sum(axis=1)[:, np.newaxis] + np.finfo(float).eps)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2f\")\n",
    "\n",
    "plt.title('Recall Confusion Matrix')\n",
    "\n",
    "# Définir les noms des labels\n",
    "plt.xticks(ticks=np.arange(len(labels)) + 0.5, labels=labels, rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(labels)) + 0.5, labels=labels, rotation=0)\n",
    "\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "cm_norm = cm_norm = mean_cm.astype('float') / (mean_cm.sum(axis=0) + np.finfo(float).eps)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2f\")\n",
    "\n",
    "plt.title('Precision Confusion Matrix')\n",
    "\n",
    "# Définir les noms des labels\n",
    "plt.xticks(ticks=np.arange(len(labels)) + 0.5, labels=labels, rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(labels)) + 0.5, labels=labels, rotation=0)\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff689d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config_file = \"/d/maboum/css-peft/configs/config.yml\"  # Change this to your actual path\n",
    "checkpoint_path = \"/scratcht/FLAIR_1/experiments/checkpoints/IL_multi_finetuning_w13_4156_3\"\n",
    "config = load_config_yaml(file_path=config_file)\n",
    "\n",
    "seed = config[\"seed\"]\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.autograd.set_detect_anomaly(True) \n",
    "random.seed(seed)\n",
    "\n",
    "# Model setup (assuming similar setup from main training code)\n",
    "selected_model = \"vit_base_patch8_224\"\n",
    "model_type = config[\"model\"]\n",
    "data_sequence =config[\"dataset\"][\"flair1\"][\"task_name\"]\n",
    "model_config = model_type[selected_model]\n",
    "im_size = model_config[\"image_size\"]\n",
    "patch_size = model_config[\"patch_size\"]\n",
    "d_model = model_config[\"d_model\"]\n",
    "n_heads = model_config[\"n_heads\"]\n",
    "n_layers = model_config[\"n_layers\"]\n",
    "d_encoder = model_config[\"d_model\"]\n",
    "n_class = config[\"dataset\"][\"flair1\"][\"n_cls\"]\n",
    "\n",
    "tuning_config = EasyDict(\n",
    "    ffn_adapt=True,\n",
    "    ffn_option=\"parallel\",\n",
    "    ffn_adapter_layernorm_option=\"none\",\n",
    "    ffn_adapter_init_option=\"lora\",\n",
    "    ffn_adapter_scalar=\"0.1\",\n",
    "    ffn_num=64,\n",
    "    d_model=d_model,\n",
    "    vpt_on=False,\n",
    "    vpt_num=1,\n",
    "    nb_task=len(data_sequence[:5]),\n",
    "    tasks=data_sequence[:5]\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = SegmenterAdapt(\n",
    "    im_size, n_layers, d_model, d_encoder, 4 * d_model, n_heads, n_class,\n",
    "    patch_size, selected_model, tuning_config=tuning_config,\n",
    "    model_name=config[\"model_name\"]\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# Load checkpoint\n",
    "model.load_pretrained_weights(model_path = checkpoint_path)\n",
    "model.eval()\n",
    "\n",
    "# Prepare test data loader\n",
    "data_config = config[\"dataset\"][\"flair1\"]\n",
    "binary = data_config[\"binary\"]\n",
    "directory_path = data_config[\"data_path\"]\n",
    "test_dataloaders = []\n",
    "train_imgs, test_imgs = [],[]\n",
    "loss_fn = torch.nn.CrossEntropyLoss().cuda()\n",
    "accuracy_fn = Accuracy(task='multiclass',num_classes=n_class).cuda()\n",
    "\n",
    "for step,domain in enumerate(tuning_config.tasks[:1]):\n",
    "    print(step , domain)\n",
    "    img = glob.glob(os.path.join(directory_path, '{}/Z*_*/img/IMG_*.tif'.format(domain)))\n",
    "    random.shuffle(img)\n",
    "    train_imgs += img[:int(len(img)*args.train_split_coef)]\n",
    "    test_imgs += img[int(len(img)*args.train_split_coef):]\n",
    "    random.shuffle(train_imgs)\n",
    "test_dataloader = create_test_dataloader(test_imgs[:1], args, data_config, binary= binary)\n",
    "\n",
    "for i, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        # Preprocess input and target\n",
    "        image = (batch['image'][:, :3, :, :] / 255.).to(device)\n",
    "        target = batch['mask'].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Assuming `image` is your image\n",
    "plt.imshow(image[0].permute(1, 2, 0).cpu() )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and a grid of subplots\n",
    "fig, axs = plt.subplots(12, 12, figsize=(20, 20))\n",
    "\n",
    "# Assuming `model` is your model and `image` is your image\n",
    "for layer_id in range(12):  # Iterate over each layer\n",
    "    attention_map_enc = model.get_attention_map_enc(image, layer_id)\n",
    "    for head_id in range(12):  # Iterate over each head\n",
    "        attention_image = attention_map_enc[0, head_id].cpu().detach().numpy()\n",
    "        \n",
    "        # Use the appropriate subplot\n",
    "        ax = axs[layer_id, head_id]\n",
    "        ax.imshow(attention_image, cmap='viridis')  # Display the image\n",
    "        ax.set_title(f'L. {layer_id + 1}, Head {head_id + 1}')  # Add a title to the subplot\n",
    "\n",
    "# Adjust the space between subplots to make the titles more readable\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the colorbar\n",
    "fig.colorbar(ax.get_images()[0], ax=axs, orientation='vertical', fraction=.1)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3160ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
